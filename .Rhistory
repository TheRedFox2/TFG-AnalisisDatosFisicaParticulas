freq2 <- hist_data[hist_data$group == 2, "count"]
# Crear un dataframe combinado con los datos de ambos grupos
group <- c(rep(1, length(freq1)), rep(2, length(freq2)))
counts <- c(freq1, freq2)
data <- data.frame(group = factor(group), counts = counts)
data <- data[data$counts > 0, ]
# Ajustar modelo Poisson completo (tasas diferentes por grupo)
modelo_completo <- glm(counts ~ group, family = poisson(link = "log"), data = data)
# Ajustar modelo Poisson reducido (una sola tasa para ambos grupos)
modelo_reducido <- glm(counts ~ 1, family = poisson, data = data)
# Calcular el LRT
LRT_stat <- 2 * (logLik(modelo_completo)[1] - logLik(modelo_reducido)[1])
p_value <- pchisq(LRT_stat, df = 1, lower.tail = FALSE)
cat("Variable:", var, "\n")
cat("Log-Likelihood Completo:", logLik(modelo_completo), "\n")
cat("Log-Likelihood Reducido:", logLik(modelo_reducido), "\n")
cat("LRT Statistic:", LRT_stat, "\n")
cat("P-Valor:", p_value, "\n")
cat("\n")
}
#Ahora la diferencia de medias normalizada
eta<-function(data1,data2) {
mu1<-mean(data1)
mu2<-mean(data2)
sd1<-sd(data1)
sd2<-sd(data2)
eta<-abs(mu2-mu1)/(sqrt(sd2^2+sd1^2))
eta
}
eta(pion[,"maxhitamp"],muon[,"maxhitamp"])
vari <- colnames(pion)[-c(1,2)]
eta_valor=data.frame()
i=1
for(var in vari){
eta_valor[i,1]<-paste(var)
eta_valor[i,2]<-eta(pion[[var]],muon[[var]])
i=i+1
}
colnames(eta_valor)<-c("Nombre variable","Eta")
eta_valor[order(eta_valor$Eta,decreasing=TRUE),]
vari<-eta_valor[,1]
for (var in vari){
cat("\n\nPara la variable llamada:", var, "\n")
d1<-ggplot(pion, aes(x=.data[[var]]))+geom_boxplot(outlier.colour="red", outlier.shape=1,outlier.size=2)+coord_flip()+labs(x=var,title =paste(var,"según pion"))
d2<-ggplot(muon, aes(x=.data[[var]]))+geom_boxplot(outlier.colour="red", outlier.shape=1,outlier.size=2)+coord_flip()+labs(x=var,title =paste(var,"según muon" ))
g<-ggarrange(d1,d2,ncol = 2,nrow = 1)
print(g)
}
pion2<-ggplot(pion,aes(x=maxhitPE,y=maxhitarea))+geom_point(size=3,color='blue')+
labs(title = "Relacion entre maximo de fotones y maxima area(pion)",x="Max fot",y="Max area")+scale_y_continuous(labels = function(x) format(x, scientific = TRUE))
muon2<-ggplot(muon,aes(x=maxhitPE,y=maxhitarea))+geom_point(size=3,color='red')+
labs(title = "Relacion entre maximo de fotones y maxima area(muon)",x="Max fot",y="Max area")+scale_y_continuous(labels = function(x) format(x, scientific = TRUE))
#Me interesa hacerle una regresion lineal porque es evidentemente lineal
pion_lm<-lm(maxhitarea ~ maxhitPE, data = pion);pion_lm
muon_lm<-lm(maxhitarea ~ maxhitPE, data = muon);muon_lm
#Ahora los dibujamos con la linea
pion2<-pion2 + geom_smooth(method='lm',color='violet',se= TRUE,size=0.8) +coord_cartesian(ylim=c(0,1.25*10^6))
muon2<-muon2 + geom_smooth(method='lm',color='violet',se= TRUE,size=0.8)+coord_cartesian(ylim=c(0,1.25*10^6))
ggarrange(pion2,muon2)
#Ahora histogramas de FlashPE
pion5<-ggplot(pion,aes(x=flashPE))+geom_histogram(bins=30,alpha=0.5,fill='red')+
labs(title = "Nº of flashPE for pions",x="Nº flashPE",y=" total")+scale_y_continuous(limits= c(0,700))
muon5<-ggplot(muon,aes(x=flashPE))+geom_histogram(alpha=0.5,fill='blue')+
labs(title = "Nº of opFlash for muons",x="Nº flashPE",y=" total")+scale_y_continuous(limits= c(0,700))
ggarrange(pion5,muon5)
#Por ultimo la matriz de correlacion
particula <- c("pion","muon")
for(p in particula){
corrmatrix<-cor(datos[datos$PDGcode==p,-c(1,2)])
print(corrmatrix)
}
#Matriz de correlación
cor_matrix <- cor(train[,-c(1,2)])  # Excluye la variable objetivo
corrplot(cor_matrix, method = "color", tl.cex = 0.7)
variables<-scan("variables.txt", what="", sep="\n")
datos <- datos[,c("EventID","PDGcode",variables)]
train<-datos[datos$EventID>=1 & datos$EventID<=14,]
test<-datos[datos$EventID>14,]
#Scatterplot
datos <- read.csv("datos_mezclados.csv")
colores <- c(rgb(248, 118, 109, maxColorValue = 255),rgb(97, 156, 255, maxColorValue = 255))
datos$color <- colores[as.numeric(factor(datos$PDGcode))]
par(xpd = TRUE)
pairs(datos[, c(variables,"maxhitPE")], col = datos$color, pch = 1,cex = 0.8)
legend("top", inset = -0.1,legend = c("Muon", "Pion"),  fill = colores, pch = 1,horiz = TRUE,title = "PDGcode",cex=0.5)
datos <- datos[, !(names(datos) %in% "color")]
#Como los piones suelen tener mas nopflash, asi clasificamos
An_corte_nopflash<-function(train,fila_test,valor_corte){
if(valor_corte<=0){
print("Valor de corte no valido")
break
}
resultado <- NULL
if (fila_test$nopflash>=valor_corte) {
resultado <- "pion"
} else {
resultado <- "muon"
}
return(resultado)
}
#los piones suelen tener mas
An_corte_meanhitrisetime<-function(train,fila_test,valor_corte){
if(valor_corte<=0){
print("Valor de corte no valido")
break
}
resultado <- NULL
if (fila_test$meanhitrisetime>=valor_corte) {
resultado <- "pion"
} else {
resultado <- "muon"
}
return(resultado)
}
#los piones tienen menos UNA VEZ LLEGAMOS AL TERCER CORTE, antes de los cortes, tienen mas.
An_corte_maxhitamp<-function(train,fila_test,valor_corte){
if(valor_corte<0){
print("Valor de corte no valido")
break
}
resultado <- NULL
if (fila_test$maxhitamp<=valor_corte) {
resultado <- "pion"
} else {
resultado <- "muon"
}
return(resultado)
}
imax<-nrow(test)
predicciones <- character(nrow(test))
ordenado<-data.frame()
for(i in 1:imax){
predicciones[i]<-An_corte_nopflash(train,test[i,], 2)
#setTxtProgressBar(pb, i)
}
matriz_confusion <- table(Prediccion = predicciones, Real = test$PDGcode)
#La reordeno porque es mas logico buscar piones, ya que son mas dificiles de hallar.
matriz_confusion <- matriz_confusion[match(c("pion", "muon"), rownames(matriz_confusion)),
match(c("pion", "muon"), colnames(matriz_confusion))]
cat("Para el valor de corte:",2," la matriz de confusion es tal que \n")
print(matriz_confusion)
cat("\n")
cat("Y sus proporciones son: \n")
print(round(prop.table(matriz_confusion)*100))
ef_pion<-(matriz_confusion["pion","pion"])/(colSums(matriz_confusion)["pion"])*100
pur_pion<-(matriz_confusion["pion","pion"])/(rowSums(matriz_confusion)["pion"])*100
cat("La eficiencia del pion es:", ef_pion, "%\n Y la pureza del pion:", pur_pion,"%\n")
# Crear un índice lógico para identificar las filas donde los valores son diferentes
diferencias <- test$PDGcode != predicciones
# Filtrar el data frame original usando el índice lógico
test_corte1 <- test[diferencias, ]
# Y ahora el corte segun meanhitrisetime donde el mejor era en 0.00425
imax<-nrow(test_corte1)
# Initiate the bar
#pb <- txtProgressBar(min = 0, max = imax, style = 3)
predicciones <- character(nrow(test_corte1))
for(i in 1:imax){
predicciones[i]<-An_corte_meanhitrisetime(train,test_corte1[i,], 0.00425)
#setTxtProgressBar(pb, i)
}
matriz_confusion <- table(Prediccion = predicciones, Real = test_corte1$PDGcode)
#La reordeno porque es mas logico buscar piones, ya que son mas dificiles de hallar.
matriz_confusion <- matriz_confusion[match(c("pion", "muon"), rownames(matriz_confusion)),
match(c("pion", "muon"), colnames(matriz_confusion))]
cat("Para el valor de corte:",2," la matriz de confusion es tal que \n")
print(matriz_confusion)
cat("\n")
cat("Y sus proporciones son: \n")
print(round(prop.table(matriz_confusion)*100))
ef_pion<-(matriz_confusion["pion","pion"])/(colSums(matriz_confusion)["pion"])*100
pur_pion<-(matriz_confusion["pion","pion"])/(rowSums(matriz_confusion)["pion"])*100
cat("La eficiencia del pion es:", ef_pion, "%\n Y la pureza del pion:", pur_pion,"%\n")
datos<-datos[,c("EventID","PDGcode",variables)]
normalizados<-datos
for(var in variables){
normalizados[[var]]<-normalize(
normalizados[[var]],
method = "range",
range = c(-1, 1),
margin = 1L,
on.constant = "quiet" )
}
par(mfcol = c(2, 3))
for (k in 3:8) {
j0 <- names(datos)[k]
x0 <- seq(min(datos[, k]), max(datos[, k]), le = 50)
for (i in 1:2) {
i0 <- levels(as.factor(datos$PDGcode))[i]
x <- datos[datos$PDGcode == i0, j0]
hist(x, proba = T, col = grey(0.8), main = paste("PDGcode", i0), xlab = j0)
lines(x0, dnorm(x0, mean(x), sd(x)), col = "blue", lwd = 2)
}
}
#Ahora los qplot
par(mfrow=c(2,3))
for (k in 3:8) {
j0 <- names(datos)[k]
x0 <- seq(min(datos[, k]), max(datos[, k]), le = 50)
for (i in 1:2) {
i0 <- levels(as.factor(datos$PDGcode))[i]
x <- datos[datos$PDGcode == i0, j0]
qqnorm(x, main = paste("PDGcode", i0, j0), pch = 19, col = i + 1)
qqline(x)
}
}
#Finalmente el test de shapiro-wilks
datos_tidy <- melt(datos, value.name = "value")
shapiro_p <- aggregate(value ~ PDGcode + variable, data = datos_tidy,
FUN = function(x){shapiro.test(x)$p.value})
shapiro_p[,shapiro_p$value>0.05]
royston_test <- mvn(data = pion[c(1:2000),c("nopflash","maxhitamp","meanhitrisetime","maxhitarea","maxhitwidth","meanhitamp")], mvnTest = "royston", multivariatePlot = "qq")
print("Comenzamos viendo el de Royston")
royston_test$multivariateNormality
print("\n\n Y ahora el de HZ")
hz_test <- mvn(data = datos[,-c(1,2,3)], mvnTest = "hz")
hz_test$multivariateNormality
print(" Voy a probar el de mardia")
set.seed(123) # Para reproducibilidad
sample_data <- datos[,-c(1,2,3)]
mardia_test <- mvn(data = sample_data, mvnTest = "mardia")
mardia_test$multivariateNormality
boxM(data = datos[, 3:8], grouping = datos[, 2])
datos<-datos[,c("EventID","PDGcode",variables)]
normalizados<-datos
for(var in variables){
normalizados[[var]]<-normalize(
normalizados[[var]],
method = "range",
range = c(-1, 1),
margin = 1L,
on.constant = "quiet" )
}
#A diferencia de lo anterior hecho, ahora train y test los tengo que tomar del df normalizado
train_norm<-normalizados[normalizados$EventID>=1 & normalizados$EventID<=14,]
test_norm<-normalizados[normalizados$EventID>14,]
train_norm$PDGcode<-as.factor(train_norm$PDGcode)
test_norm$PDGcode<-as.factor(test_norm$PDGcode)
#Voy a quedarme solo con las 4 mejores variables, ya que el resultado mejora al no tener sobredimensionalidad
train_norm<-train_norm[,c(1:6)]
test_norm<-test_norm[,c(1:6)]
clasificador_knn <- train(PDGcode ~ .,data =train_norm[,-c(1)],method = "knn", trControl = trainControl(method = "cv", number = 10), tuneGrid = expand.grid(k = 21), prob = TRUE,preProcess = NULL )
prediccion <- predict(clasificador_knn, test_norm)
#A continuacion lo evidente: la matriz de confusion
mc<- confusionMatrix(factor(prediccion) , factor(test_norm$PDGcode))
mc$table
cat("Y ahora las proporciones  \n")
round(prop.table(mc$table)*100,2)
mc$byClass
paste0("Eficiencia x Pureza de: ", mc$byClass["Sensitivity"]*mc$byClass["Specificity"])
prob_knn <- predict(clasificador_knn, test_norm, type = "prob")
roc_curve <- roc(response = test_norm$PDGcode, predictor =prob_knn$pion, levels = levels(test_norm$PDGcode))
auc_value <- auc(roc_curve)
print(paste("AUC:", auc_value))
ggplot(data = data.frame(TPR = roc_curve$sensitivities,
FPR = 1 - roc_curve$specificities),
aes(x = FPR, y = TPR)) +
geom_line(color = "blue", size = 1) +
geom_abline(linetype = "dashed", color = "red") + # Línea de referencia diagonal
labs(title = "ROC Curve - K Nearest Neighbor",
x = "False Positive Rate (1 - Specificity)",
y = "True Positive Rate (Sensitivity)") +
theme_minimal()+
annotate("text", x = 0.8, y = 0.2, label = paste0("AUC = ",round(auc_value,4)), color = "blue", vjust = 1.5)
#En este chunk, escojo las variables, normalizo mis datos para tenerlo todo tipificado y escalado, y creo los data frame de training y de test sobre los que construir el modelo en un 70%-30%, por ello escojo en train los de eventid menor de 14 y en test los de mayor.
datos_variables <- c("EventID","PDGcode",variables)
datos <- datos[,datos_variables]
normalizados<-datos
# for(var in variables){
# normalizados[[var]]<-normalize(
#   normalizados[[var]],
#   method = "range",
#   range = c(-1, 1),
#   margin = 1L,
#   on.constant = "quiet" )
# }
#A diferencia de lo anterior hecho, ahora train y test los tengo que tomar del df normalizado
train<-normalizados[normalizados$EventID>=1 & normalizados$EventID<=14,]
test<-normalizados[normalizados$EventID>14,]
train$PDGcode<-as.factor(train$PDGcode)
test$PDGcode<-as.factor(test$PDGcode)
#Reordeno el factor porque así me prioriza el pion, que es el que nos interesa clasificar con mayor interes
train$PDGcode <- factor(train$PDGcode, levels = c("pion", "muon"))
test$PDGcode <- factor(test$PDGcode, levels = c("pion", "muon"))
#Quitando maxhitwidth me da mejores resultados
model_qda <- qda(PDGcode ~ ., data = train[,-c(1,7)])
prediccion_qda <- predict(model_qda, test)
prediccion_qda_mod <- ifelse(prediccion_qda$posterior[, "muon"] >= 0.5, "muon", "pion")
# Convertir a factor con los niveles correctos
prediccion_qda_mod <- factor(prediccion_qda_mod, levels = levels(test$PDGcode))
# Matriz de confusión
(mat_confusion <- confusionMatrix(prediccion_qda_mod, test$PDGcode))
prop.table(mat_confusion$table)*100
mat_confusion$byClass
paste0("Eficiencia x Pureza de: ", mat_confusion$byClass["Sensitivity"]*mat_confusion$byClass["Specificity"])
# Y la curva ROC
# Obtener probabilidades de la clase "pion"
prob_qda <- prediccion_qda$posterior[,2]
# Calcula la curva ROC
roc_curve <- roc(test$PDGcode, prob_qda)
auc_value <- auc(roc_curve)
# Graficar la curva ROCplot(roc_curve,
ggplot(data = data.frame(TPR = roc_curve$sensitivities,
FPR = 1 - roc_curve$specificities),
aes(x = FPR, y = TPR)) +
geom_line(color = "blue", size = 1) +
geom_abline(linetype = "dashed", color = "red") + # Línea de referencia diagonal
labs(title = "ROC Curve - QDA",
x = "False Positive Rate (1 - Specificity)",
y = "True Positive Rate (Sensitivity)") +
theme_minimal()+
annotate("text", x = 0.8, y = 0.2, label = paste0("AUC = ",round(auc_value,4)), color = "blue", vjust = 1.5)
#Descomentar si interesase estudiar la probabilidad de que sea pion, poniendo de referencia la clase muon
# train$PDGcode <- relevel(train$PDGcode, ref = "muon")
# test$PDGcode <- relevel(test$PDGcode, ref = "muon")
model_logit <- glm(PDGcode ~ (nopflash + meanhitrisetime + maxhitamp + maxhitarea + maxhitwidth + meanhitamp), family = binomial(link = "logit"), data = train[,-c(1)])
#Como el segundo nivel es muon, se ve que al hacer el modelo glm(), la prob que asocia es respecto al segundo nivel.
prob_logit <- predict(model_logit, test, type = "response")
prediccion_logit <- ifelse(prob_logit >= 0.5, "muon", "pion")
prediccion_logit <- factor(prediccion_logit, levels = levels(test$PDGcode))
(mat_confusion <- confusionMatrix(prediccion_logit,test$PDGcode))
prop.table(mat_confusion$table)*100
mat_confusion$byClass
paste0("Eficiencia x Pureza de: ", mat_confusion$byClass["Sensitivity"]*mat_confusion$byClass["Specificity"])
# Crear el objeto ROC
roc_curve <- roc(response = test$PDGcode, predictor = prob_logit, levels = levels(test$PDGcode))
auc_value <- auc(roc_curve)
print(paste("AUC:", auc_value))
# Graficar la curva ROC con ggplot2
ggplot(data = data.frame(TPR = roc_curve$sensitivities,
FPR = 1 - roc_curve$specificities),
aes(x = FPR, y = TPR)) +
geom_line(color = "blue", size = 1) +
geom_abline(linetype = "dashed", color = "red") + # Línea de referencia diagonal
labs(title = "ROC Curve - Logistic Regression",
x = "False Positive Rate (1 - Specificity)",
y = "True Positive Rate (Sensitivity)") +
theme_minimal()+
annotate("text", x = 0.8, y = 0.2, label = paste0("AUC = ",round(auc_value,4)), color = "blue", vjust = 1.5)
# Calcular y mostrar el AUC
#HE VISTO QUE QUITANDO MAXHITWIDTH EL MODELO MEJORA!!!!!
#Y ADEMAS COMO HAY QUE QUITAR MEANHITRISETIME PORQUE NO ES SIGNIFICATIVO!
#El modelo completo quedaría MEJOR con esto, con un AUC del 0.715
model_logit <- glm(PDGcode ~ (nopflash  + maxhitamp + maxhitarea + meanhitamp), family = binomial(link = "logit"), data = train[,-c(1)])
levels(test$PDGcode)
model_logit
#Como el segundo nivel es muon, se ve que al hacer el modelo glm(), la prob que asocia es respecto al segundo nivel.
prob_logit <- predict(model_logit, test, type = "response")
prediccion_logit <- ifelse(prob_logit >= 0.5, "muon", "pion")
prediccion_logit <- factor(prediccion_logit, levels = levels(test$PDGcode))
#Parece que poner de threshold el 0.6 es la mejor opción, y cuadra bastante mas con la curva ROC
(mat_confusion <- confusionMatrix(prediccion_logit,test$PDGcode))
prop.table(mat_confusion$table)*100
mat_confusion$byClass
paste0("Eficiencia x Pureza de: ", mat_confusion$byClass["Sensitivity"]*mat_confusion$byClass["Specificity"])
probabilidades <- seq(0,1, by = 0.05)
auxiliar <- vector( length = length(probabilidades))
auxiliar_2 <- vector( length = length(probabilidades))
for(i in probabilidades){
prob_logit <- predict(model_logit, test, type = "response")
prediccion_logit <- ifelse(prob_logit >= i, "muon", "pion")
prediccion_logit <- factor(prediccion_logit, levels = levels(test$PDGcode))
mat_confusion <- confusionMatrix(prediccion_logit,test$PDGcode)
auxiliar[i*20] <- mat_confusion$byClass["Sensitivity"]
auxiliar_2[i*20] <- mat_confusion$byClass["Specificity"]
}
plot(probabilidades, y =auxiliar, main="Eficiencia * pureza", col = "red", pch = 19)
points(probabilidades, y = auxiliar_2,col = "blue", pch = 19)
legend("topleft", legend = c("Eficiencia", "Pureza"), col = c("red","blue"))
roc_curve <- roc(response = test$PDGcode, predictor = prob_logit, levels = levels(test$PDGcode))
auc_value <- auc(roc_curve)
print(paste("AUC:", auc_value))
# Graficar la curva ROC con ggplot2
ggplot(data = data.frame(TPR = roc_curve$sensitivities,
FPR = 1 - roc_curve$specificities),
aes(x = FPR, y = TPR)) +
geom_line(color = "blue", size = 1) +
geom_abline(linetype = "dashed", color = "red") + # Línea de referencia diagonal
labs(title = "ROC Curve - Logistic Regression",
x = "False Positive Rate (1 - Specificity)",
y = "True Positive Rate (Sensitivity)") +
theme_minimal()+
annotate("text", x = 0.8, y = 0.2, label = paste0("AUC = ",round(auc_value,4)), color = "blue", vjust = 1.5)
#El AUC de esto es de 0.6, bastante malo, pero esta es interesante para la pureza
model_logit <- glm(PDGcode ~ (nopflash ), family = binomial(link = "logit"), data = train[,-c(1)])
levels(test$PDGcode)
#Como el segundo nivel es muon, se ve que al hacer el modelo glm(), la prob que asocia es respecto al segundo nivel.
prob_logit <- predict(model_logit, test, type = "response")
prediccion_logit <- ifelse(prob_logit >= 0.5, "muon", "pion")
prediccion_logit <- factor(prediccion_logit, levels = levels(test$PDGcode))
#Parece que poner de threshold el 0.6 es la mejor opción, y cuadra bastante mas con la curva ROC
(mat_confusion <- confusionMatrix(prediccion_logit,test$PDGcode))
prop.table(mat_confusion$table)*100
mat_confusion$byClass
paste0("Eficiencia x Pureza de: ", mat_confusion$byClass["Sensitivity"]*mat_confusion$byClass["Specificity"])
roc_curve <- roc(response = test$PDGcode, predictor = prob_logit, levels = levels(test$PDGcode))
auc_value <- auc(roc_curve)
print(paste("AUC:", auc_value))
# Graficar la curva ROC con ggplot2
ggplot(data = data.frame(TPR = roc_curve$sensitivities,
FPR = 1 - roc_curve$specificities),
aes(x = FPR, y = TPR)) +
geom_line(color = "blue", size = 1) +
geom_abline(linetype = "dashed", color = "red") + # Línea de referencia diagonal
labs(title = "ROC Curve - Logistic Regression",
x = "False Positive Rate (1 - Specificity)",
y = "True Positive Rate (Sensitivity)") +
theme_minimal()+
annotate("text", x = 0.8, y = 0.2, label = paste0("AUC = ",round(auc_value,4)), color = "blue", vjust = 1.5)
train_2 <- train[train$nopflash <=2,]
test_2 <- test[test$nopflash <=2,]
summary(train_2)
#Quitando maxhitwidth me da mejores resultados
model_qda <- qda(PDGcode ~ ., data = train_2[,-c(1,7)])
prediccion_qda <- predict(model_qda, test_2)
prediccion_qda_mod <- ifelse(prediccion_qda$posterior[, "muon"] >= 0.5, "muon", "pion")
# Convertir a factor con los niveles correctos
prediccion_qda_mod <- factor(prediccion_qda_mod, levels = levels(test_2$PDGcode))
# Matriz de confusión
(mat_confusion <- confusionMatrix(prediccion_qda_mod, test_2$PDGcode))
prop.table(mat_confusion$table)*100
mat_confusion$byClass
paste0("Eficiencia x Pureza de: ", mat_confusion$byClass["Sensitivity"]*mat_confusion$byClass["Specificity"])
# Obtener probabilidades de la clase "pion"
prob_qda <- prediccion_qda$posterior[,2]
# Calcula la curva ROC
roc_curve <- roc(test_2$PDGcode, prob_qda)
auc(roc_curve)
# Graficar la curva ROCplot(roc_curve,
ggplot(data = data.frame(TPR = roc_curve$sensitivities,
FPR = 1 - roc_curve$specificities),
aes(x = FPR, y = TPR)) +
geom_line(color = "blue", size = 1) +
geom_abline(linetype = "dashed", color = "red") + # Línea de referencia diagonal
labs(title = "ROC Curve - QDA",
x = "False Positive Rate (1 - Specificity)",
y = "True Positive Rate (Sensitivity)") +
theme_minimal()+
annotate("text", x = 0.8, y = 0.2, label = paste0("AUC = ",round(auc_value,4)), color = "blue", vjust = 1.5)
model_logit <- glm(PDGcode ~ (nopflash + meanhitrisetime + maxhitamp + maxhitarea + maxhitwidth + meanhitamp), family = binomial(link = "logit"), data = train_2[,-c(1)])
levels(test_2$PDGcode)
#Como el segundo nivel es muon, se ve que al hacer el modelo glm(), la prob que asocia es respecto al segundo nivel.
prob_logit <- predict(model_logit, test_2, type = "response")
prediccion_logit <- ifelse(prob_logit >= 0.5, "muon", "pion")
prediccion_logit <- factor(prediccion_logit, levels = levels(test_2$PDGcode))
#Parece que poner de threshold el 0.6 es la mejor opción, y cuadra bastante mas con la curva ROC
(mat_confusion <- confusionMatrix(prediccion_logit,test_2$PDGcode))
prop.table(mat_confusion$table)*100
mat_confusion$byClass
paste0("Eficiencia x Pureza de: ", mat_confusion$byClass["Sensitivity"]*mat_confusion$byClass["Specificity"])
# Obtener probabilidades de la clase "pion"
auc_value <- auc(roc_curve)
print(paste("AUC:", auc_value))
# Crear el objeto ROC
roc_curve <- roc(response = test_2$PDGcode, predictor = prob_logit, levels = levels(test_2$PDGcode))
# Graficar la curva ROC con ggplot2
ggplot(data = data.frame(TPR = roc_curve$sensitivities,
FPR = 1 - roc_curve$specificities),
aes(x = FPR, y = TPR)) +
geom_line(color = "blue", size = 1) +
geom_abline(linetype = "dashed", color = "red") + # Línea de referencia diagonal
labs(title = "ROC Curve - Logistic Regression",
x = "False Positive Rate (1 - Specificity)",
y = "True Positive Rate (Sensitivity)") +
theme_minimal()+
annotate("text", x = 0.8, y = 0.2, label = paste0("AUC = ",round(auc_value,4)), color = "blue", vjust = 1.5)
# Calcular y mostrar el AUC
#HE VISTO QUE QUITANDO MAXHITWIDTH EL MODELO MEJORA!!!!!
#Y ADEMAS COMO HAY QUE QUITAR MEANHITRISETIME PORQUE NO ES SIGNIFICATIVO!
#El modelo completo quedaría MEJOR con esto, con un AUC del 0.715
model_logit <- glm(PDGcode ~ (nopflash  + maxhitamp + maxhitarea + meanhitamp), family = binomial(link = "logit"), data = train_2[,-c(1)])
levels(test_2$PDGcode)
#Como el segundo nivel es muon, se ve que al hacer el modelo glm(), la prob que asocia es respecto al segundo nivel.
#PLOTEO LOS GRAFICOS DE EF*PUR PARA VER SI EL MEJOR PUNTO ES 0.5
probabilidades <- seq(0,1, by = 0.05)
auxiliar <- vector( length = length(probabilidades))
auxiliar_2 <- vector( length = length(probabilidades))
for(i in probabilidades){
prob_logit <- predict(model_logit, test_2, type = "response")
prediccion_logit <- ifelse(prob_logit >= i, "muon", "pion")
prediccion_logit <- factor(prediccion_logit, levels = levels(test_2$PDGcode))
mat_confusion <- confusionMatrix(prediccion_logit,test_2$PDGcode)
auxiliar[i*20] <- mat_confusion$byClass["Sensitivity"]
auxiliar_2[i*20] <- mat_confusion$byClass["Specificity"]
}
plot(probabilidades, y =auxiliar, main="Eficiencia * pureza", col = "red", pch = 19)
points(probabilidades, y = auxiliar_2,col = "blue", pch = 19)
legend("topleft", legend = c("Eficiencia", "Pureza"), col = c("red","blue"))
prob_logit <- predict(model_logit, test_2, type = "response")
prediccion_logit <- ifelse(prob_logit >= 0.5, "muon", "pion")
prediccion_logit <- factor(prediccion_logit, levels = levels(test_2$PDGcode))
#Parece que poner de threshold el 0.6 es la mejor opción, y cuadra bastante mas con la curva ROC
(mat_confusion <- confusionMatrix(prediccion_logit,test_2$PDGcode))
prop.table(mat_confusion$table)*100
mat_confusion$byClass
paste0("Eficiencia x Pureza de: ", mat_confusion$byClass["Sensitivity"]*mat_confusion$byClass["Specificity"])
# Obtener probabilidades de la clase "pion"
auc_value <- auc(roc_curve)
print(paste("AUC:", auc_value))
# Crear el objeto ROC
roc_curve <- roc(response = test_2$PDGcode, predictor = prob_logit, levels = levels(test_2$PDGcode))
# Graficar la curva ROC con ggplot2
ggplot(data = data.frame(TPR = roc_curve$sensitivities,
FPR = 1 - roc_curve$specificities),
aes(x = FPR, y = TPR)) +
geom_line(color = "blue", size = 1) +
geom_abline(linetype = "dashed", color = "red") + # Línea de referencia diagonal
labs(title = "ROC Curve - Logistic Regression",
x = "False Positive Rate (1 - Specificity)",
y = "True Positive Rate (Sensitivity)") +
theme_minimal()+
annotate("text", x = 0.8, y = 0.2, label = paste0("AUC = ",round(auc_value,4)), color = "blue", vjust = 1.5)
# Calcular y mostrar el AUC
